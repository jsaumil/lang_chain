{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c617d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c95a8a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_id = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "save_dir = r\"F:\\python\\model\\cardiffnlp_sentiment\"  # your custom folder\n",
    "\n",
    "# Download and save locally\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "model.save_pretrained(save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97846e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) positive 0.8466\n",
      "2) neutral 0.1458\n",
      "3) negative 0.0076\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    " \n",
    " \n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# download label mapping\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n",
    "\n",
    "text = \"Good night ðŸ˜Š\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "# # TF\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "\n",
    "# text = \"Good night ðŸ˜Š\"\n",
    "# encoded_input = tokenizer(text, return_tensors='tf')\n",
    "# output = model(encoded_input)\n",
    "# scores = output[0][0].numpy()\n",
    "# scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdbf40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I love working with Hugging Face!\n",
      "Sentiment: Positive, Score: 0.9908\n",
      "\n",
      "Text: This is the worst experience ever.\n",
      "Sentiment: Negative, Score: 0.9766\n",
      "\n",
      "Text: It's okay, not great but not bad either.\n",
      "Sentiment: Positive, Score: 0.7400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# Path to your local model folder\n",
    "model_path = r\"F:\\python\\model\\cardiffnlp_sentiment\"\n",
    "\n",
    "# Load tokenizer and model from local directory\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Create sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Test sentences\n",
    "sentences = [\n",
    "    \"I love working with Hugging Face!\",\n",
    "    \"This is the worst experience ever.\",\n",
    "    \"It's okay, not great but not bad either.\"\n",
    "]\n",
    "\n",
    "# Map Hugging Face labels to real sentiments\n",
    "label_map = {\n",
    "    \"LABEL_0\": \"Negative\",\n",
    "    \"LABEL_1\": \"Neutral\",\n",
    "    \"LABEL_2\": \"Positive\"\n",
    "}\n",
    "\n",
    "# Run and print results\n",
    "for text in sentences:\n",
    "    result = sentiment_pipeline(text)[0]\n",
    "    label = label_map[result[\"label\"]]\n",
    "    print(f\"Text: {text}\\nSentiment: {label}, Score: {result['score']:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38570bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "model_path = r\"F:\\python\\model\\cardiffnlp_sentiment\"\n",
    "\n",
    "# Load tokenizer and model from local directory\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Create sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "sentence= \"I love working with Hugging Face!\"\n",
    "\n",
    "result=sentiment_pipeline(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e12b32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0978762a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LABEL_2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcdbd052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saumi\\anaconda3\\envs\\langchain-llama\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\saumi\\.cache\\huggingface\\hub\\models--tabularisai--multilingual-sentiment-analysis. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I absolutely love the new design of this app!\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: The customer service was disappointing.\n",
      "Sentiment: Negative\n",
      "\n",
      "Text: The weather is fine, nothing special.\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: è¿™å®¶é¤åŽ…çš„èœå‘³é“éžå¸¸æ£’ï¼\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: æˆ‘å¯¹ä»–çš„å›žç­”å¾ˆå¤±æœ›ã€‚\n",
      "Sentiment: Negative\n",
      "\n",
      "Text: å¤©æ°”ä»Šå¤©ä¸€èˆ¬ã€‚\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: Â¡Me encanta cÃ³mo quedÃ³ la decoraciÃ³n!\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: El servicio fue terrible y muy lento.\n",
      "Sentiment: Very Negative\n",
      "\n",
      "Text: El libro estuvo mÃ¡s o menos.\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: Ø§Ù„Ø®Ø¯Ù…Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„ÙÙ†Ø¯Ù‚ Ø±Ø§Ø¦Ø¹Ø© Ø¬Ø¯Ù‹Ø§!\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: Ù„Ù… ÙŠØ¹Ø¬Ø¨Ù†ÙŠ Ø§Ù„Ø·Ø¹Ø§Ù… ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø·Ø¹Ù….\n",
      "Sentiment: Negative\n",
      "\n",
      "Text: ÙƒØ§Ù†Øª Ø§Ù„Ø±Ø­Ù„Ø© Ø¹Ø§Ø¯ÙŠØ©ã€‚\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: ÐœÐµÐ½Ñ– Ð´ÑƒÐ¶Ðµ ÑÐ¿Ð¾Ð´Ð¾Ð±Ð°Ð»Ð°ÑÑ Ñ†Ñ Ð²Ð¸ÑÑ‚Ð°Ð²Ð°!\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: ÐžÐ±ÑÐ»ÑƒÐ³Ð¾Ð²ÑƒÐ²Ð°Ð½Ð½Ñ Ð±ÑƒÐ»Ð¾ Ð¶Ð°Ñ…Ð»Ð¸Ð²Ð¸Ð¼.\n",
      "Sentiment: Very Negative\n",
      "\n",
      "Text: ÐšÐ½Ð¸Ð³Ð° Ð±ÑƒÐ»Ð° Ð¿Ð¾ÑÐµÑ€ÐµÐ´Ð½ÑŒÐ¾ÑŽã€‚\n",
      "Sentiment: Negative\n",
      "\n",
      "Text: à¤¯à¤¹ à¤œà¤—à¤¹ à¤¸à¤š à¤®à¥‡à¤‚ à¤…à¤¦à¥à¤­à¥à¤¤ à¤¹à¥ˆ!\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: à¤¯à¤¹ à¤…à¤¨à¥à¤­à¤µ à¤¬à¤¹à¥à¤¤ à¤–à¤°à¤¾à¤¬ à¤¥à¤¾à¥¤\n",
      "Sentiment: Very Negative\n",
      "\n",
      "Text: à¤«à¤¿à¤²à¥à¤® à¤ à¥€à¤•-à¤ à¤¾à¤• à¤¥à¥€à¥¤\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: à¦à¦–à¦¾à¦¨à¦•à¦¾à¦° à¦ªà¦°à¦¿à¦¬à§‡à¦¶ à¦…à¦¸à¦¾à¦§à¦¾à¦°à¦£!\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: à¦¸à§‡à¦¬à¦¾à¦° à¦®à¦¾à¦¨ à¦à¦•à§‡à¦¬à¦¾à¦°à§‡à¦‡ à¦–à¦¾à¦°à¦¾à¦ªà¥¤\n",
      "Sentiment: Very Negative\n",
      "\n",
      "Text: à¦–à¦¾à¦¬à¦¾à¦°à¦Ÿà¦¾ à¦®à§‹à¦Ÿà¦¾à¦®à§à¦Ÿà¦¿ à¦›à¦¿à¦²à¥¤\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: Este livro Ã© fantÃ¡stico! Eu aprendi muitas coisas novas e inspiradoras.\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: NÃ£o gostei do produto, veio quebrado.\n",
      "Sentiment: Very Negative\n",
      "\n",
      "Text: O filme foi ok, nada de especial.\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: ã“ã®ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã®æ–™ç†ã¯æœ¬å½“ã«ç¾Žå‘³ã—ã„ã§ã™ï¼\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: ã“ã®ãƒ›ãƒ†ãƒ«ã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ãŒã£ã‹ã‚Šã—ã¾ã—ãŸã€‚\n",
      "Sentiment: Negative\n",
      "\n",
      "Text: å¤©æ°—ã¯ã¾ã‚ã¾ã‚ã§ã™ã€‚\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: Ð¯ Ð² Ð²Ð¾ÑÑ‚Ð¾Ñ€Ð³Ðµ Ð¾Ñ‚ ÑÑ‚Ð¾Ð³Ð¾ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð³Ð°Ð´Ð¶ÐµÑ‚Ð°!\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: Ð­Ñ‚Ð¾Ñ‚ ÑÐµÑ€Ð²Ð¸Ñ Ð¾ÑÑ‚Ð°Ð²Ð¸Ð» Ñƒ Ð¼ÐµÐ½Ñ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ€Ð°Ð·Ð¾Ñ‡Ð°Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ.\n",
      "Sentiment: Very Negative\n",
      "\n",
      "Text: Ð’ÑÑ‚Ñ€ÐµÑ‡Ð° Ð±Ñ‹Ð»Ð° Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾Ð¹, Ð½Ð¸Ñ‡ÐµÐ³Ð¾ Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾Ð³Ð¾.\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: J'adore ce restaurant, c'est excellent !\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: L'attente Ã©tait trop longue et frustrante.\n",
      "Sentiment: Negative\n",
      "\n",
      "Text: Le film Ã©tait moyen, sans plus.\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: Bu otelin manzarasÄ±na bayÄ±ldÄ±m!\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: ÃœrÃ¼n tam bir hayal kÄ±rÄ±klÄ±ÄŸÄ±ydÄ±.\n",
      "Sentiment: Very Negative\n",
      "\n",
      "Text: Konser fena deÄŸildi, ortalamaydÄ±.\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: Adoro questo posto, Ã¨ fantastico!\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: Il servizio clienti Ã¨ stato pessimo.\n",
      "Sentiment: Very Negative\n",
      "\n",
      "Text: La cena era nella media.\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: Uwielbiam tÄ™ restauracjÄ™, jedzenie jest Å›wietne!\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: ObsÅ‚uga klienta byÅ‚a rozczarowujÄ…ca.\n",
      "Sentiment: Negative\n",
      "\n",
      "Text: Pogoda jest w porzÄ…dku, nic szczegÃ³lnego.\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: Ang ganda ng lugar na ito, sobrang aliwalas!\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: Hindi maganda ang serbisyo nila dito.\n",
      "Sentiment: Negative\n",
      "\n",
      "Text: Maayos lang ang palabas, walang espesyal.\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: Ik ben echt blij met mijn nieuwe aankoop!\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: De klantenservice was echt slecht.\n",
      "Sentiment: Negative\n",
      "\n",
      "Text: De presentatie was gewoon okÃ©, niet bijzonder.\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: Saya suka makanan di sini, sangat sedap!\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: Pengalaman ini sangat mengecewakan.\n",
      "Sentiment: Very Negative\n",
      "\n",
      "Text: Hari ini cuacanya biasa sahaja.\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: ì´ ê°€ê²Œì˜ ì¼€ì´í¬ëŠ” ì •ë§ ë§›ìžˆì–´ìš”!\n",
      "Sentiment: Very Positive\n",
      "\n",
      "Text: ì„œë¹„ìŠ¤ê°€ ë„ˆë¬´ ë³„ë¡œì˜€ì–´ìš”.\n",
      "Sentiment: Negative\n",
      "\n",
      "Text: ë‚ ì”¨ê°€ ê·¸ì € ê·¸ë ‡ë„¤ìš”.\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: Ich find dÃ¤ Service i de Beiz mega guet!\n",
      "Sentiment: Positive\n",
      "\n",
      "Text: DÃ¤s EsÃ¤ het mir nÃ¶d gfalle.\n",
      "Sentiment: Very Negative\n",
      "\n",
      "Text: D WÃ¤tter hÃ¼t isch so naja.\n",
      "Sentiment: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"tabularisai/multilingual-sentiment-analysis\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "def predict_sentiment(texts):\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    sentiment_map = {0: \"Very Negative\", 1: \"Negative\", 2: \"Neutral\", 3: \"Positive\", 4: \"Very Positive\"}\n",
    "    return [sentiment_map[p] for p in torch.argmax(probabilities, dim=-1).tolist()]\n",
    "\n",
    "texts = [\n",
    "    # English\n",
    "    \"I absolutely love the new design of this app!\", \"The customer service was disappointing.\", \"The weather is fine, nothing special.\",\n",
    "    # Chinese\n",
    "    \"è¿™å®¶é¤åŽ…çš„èœå‘³é“éžå¸¸æ£’ï¼\", \"æˆ‘å¯¹ä»–çš„å›žç­”å¾ˆå¤±æœ›ã€‚\", \"å¤©æ°”ä»Šå¤©ä¸€èˆ¬ã€‚\",\n",
    "    # Spanish\n",
    "    \"Â¡Me encanta cÃ³mo quedÃ³ la decoraciÃ³n!\", \"El servicio fue terrible y muy lento.\", \"El libro estuvo mÃ¡s o menos.\",\n",
    "    # Arabic\n",
    "    \"Ø§Ù„Ø®Ø¯Ù…Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„ÙÙ†Ø¯Ù‚ Ø±Ø§Ø¦Ø¹Ø© Ø¬Ø¯Ù‹Ø§!\", \"Ù„Ù… ÙŠØ¹Ø¬Ø¨Ù†ÙŠ Ø§Ù„Ø·Ø¹Ø§Ù… ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø·Ø¹Ù….\", \"ÙƒØ§Ù†Øª Ø§Ù„Ø±Ø­Ù„Ø© Ø¹Ø§Ø¯ÙŠØ©ã€‚\",\n",
    "    # Ukrainian\n",
    "    \"ÐœÐµÐ½Ñ– Ð´ÑƒÐ¶Ðµ ÑÐ¿Ð¾Ð´Ð¾Ð±Ð°Ð»Ð°ÑÑ Ñ†Ñ Ð²Ð¸ÑÑ‚Ð°Ð²Ð°!\", \"ÐžÐ±ÑÐ»ÑƒÐ³Ð¾Ð²ÑƒÐ²Ð°Ð½Ð½Ñ Ð±ÑƒÐ»Ð¾ Ð¶Ð°Ñ…Ð»Ð¸Ð²Ð¸Ð¼.\", \"ÐšÐ½Ð¸Ð³Ð° Ð±ÑƒÐ»Ð° Ð¿Ð¾ÑÐµÑ€ÐµÐ´Ð½ÑŒÐ¾ÑŽã€‚\",\n",
    "    # Hindi\n",
    "    \"à¤¯à¤¹ à¤œà¤—à¤¹ à¤¸à¤š à¤®à¥‡à¤‚ à¤…à¤¦à¥à¤­à¥à¤¤ à¤¹à¥ˆ!\", \"à¤¯à¤¹ à¤…à¤¨à¥à¤­à¤µ à¤¬à¤¹à¥à¤¤ à¤–à¤°à¤¾à¤¬ à¤¥à¤¾à¥¤\", \"à¤«à¤¿à¤²à¥à¤® à¤ à¥€à¤•-à¤ à¤¾à¤• à¤¥à¥€à¥¤\",\n",
    "    # Bengali\n",
    "    \"à¦à¦–à¦¾à¦¨à¦•à¦¾à¦° à¦ªà¦°à¦¿à¦¬à§‡à¦¶ à¦…à¦¸à¦¾à¦§à¦¾à¦°à¦£!\", \"à¦¸à§‡à¦¬à¦¾à¦° à¦®à¦¾à¦¨ à¦à¦•à§‡à¦¬à¦¾à¦°à§‡à¦‡ à¦–à¦¾à¦°à¦¾à¦ªà¥¤\", \"à¦–à¦¾à¦¬à¦¾à¦°à¦Ÿà¦¾ à¦®à§‹à¦Ÿà¦¾à¦®à§à¦Ÿà¦¿ à¦›à¦¿à¦²à¥¤\",\n",
    "    # Portuguese\n",
    "    \"Este livro Ã© fantÃ¡stico! Eu aprendi muitas coisas novas e inspiradoras.\", \n",
    "    \"NÃ£o gostei do produto, veio quebrado.\", \"O filme foi ok, nada de especial.\",\n",
    "    # Japanese\n",
    "    \"ã“ã®ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã®æ–™ç†ã¯æœ¬å½“ã«ç¾Žå‘³ã—ã„ã§ã™ï¼\", \"ã“ã®ãƒ›ãƒ†ãƒ«ã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ãŒã£ã‹ã‚Šã—ã¾ã—ãŸã€‚\", \"å¤©æ°—ã¯ã¾ã‚ã¾ã‚ã§ã™ã€‚\",\n",
    "    # Russian\n",
    "    \"Ð¯ Ð² Ð²Ð¾ÑÑ‚Ð¾Ñ€Ð³Ðµ Ð¾Ñ‚ ÑÑ‚Ð¾Ð³Ð¾ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð³Ð°Ð´Ð¶ÐµÑ‚Ð°!\", \"Ð­Ñ‚Ð¾Ñ‚ ÑÐµÑ€Ð²Ð¸Ñ Ð¾ÑÑ‚Ð°Ð²Ð¸Ð» Ñƒ Ð¼ÐµÐ½Ñ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ€Ð°Ð·Ð¾Ñ‡Ð°Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ.\", \"Ð’ÑÑ‚Ñ€ÐµÑ‡Ð° Ð±Ñ‹Ð»Ð° Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾Ð¹, Ð½Ð¸Ñ‡ÐµÐ³Ð¾ Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾Ð³Ð¾.\",\n",
    "    # French\n",
    "    \"J'adore ce restaurant, c'est excellent !\", \"L'attente Ã©tait trop longue et frustrante.\", \"Le film Ã©tait moyen, sans plus.\",\n",
    "    # Turkish\n",
    "    \"Bu otelin manzarasÄ±na bayÄ±ldÄ±m!\", \"ÃœrÃ¼n tam bir hayal kÄ±rÄ±klÄ±ÄŸÄ±ydÄ±.\", \"Konser fena deÄŸildi, ortalamaydÄ±.\",\n",
    "    # Italian\n",
    "    \"Adoro questo posto, Ã¨ fantastico!\", \"Il servizio clienti Ã¨ stato pessimo.\", \"La cena era nella media.\",\n",
    "    # Polish\n",
    "    \"Uwielbiam tÄ™ restauracjÄ™, jedzenie jest Å›wietne!\", \"ObsÅ‚uga klienta byÅ‚a rozczarowujÄ…ca.\", \"Pogoda jest w porzÄ…dku, nic szczegÃ³lnego.\",\n",
    "    # Tagalog\n",
    "    \"Ang ganda ng lugar na ito, sobrang aliwalas!\", \"Hindi maganda ang serbisyo nila dito.\", \"Maayos lang ang palabas, walang espesyal.\",\n",
    "    # Dutch\n",
    "    \"Ik ben echt blij met mijn nieuwe aankoop!\", \"De klantenservice was echt slecht.\", \"De presentatie was gewoon okÃ©, niet bijzonder.\",\n",
    "    # Malay\n",
    "    \"Saya suka makanan di sini, sangat sedap!\", \"Pengalaman ini sangat mengecewakan.\", \"Hari ini cuacanya biasa sahaja.\",\n",
    "    # Korean\n",
    "    \"ì´ ê°€ê²Œì˜ ì¼€ì´í¬ëŠ” ì •ë§ ë§›ìžˆì–´ìš”!\", \"ì„œë¹„ìŠ¤ê°€ ë„ˆë¬´ ë³„ë¡œì˜€ì–´ìš”.\", \"ë‚ ì”¨ê°€ ê·¸ì € ê·¸ë ‡ë„¤ìš”.\",\n",
    "    # Swiss German\n",
    "    \"Ich find dÃ¤ Service i de Beiz mega guet!\", \"DÃ¤s EsÃ¤ het mir nÃ¶d gfalle.\", \"D WÃ¤tter hÃ¼t isch so naja.\"\n",
    "]\n",
    "\n",
    "for text, sentiment in zip(texts, predict_sentiment(texts)):\n",
    "    print(f\"Text: {text}\\nSentiment: {sentiment}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1969947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is **New Delhi**. It is a city located within the **National Capital Territory of Delhi** (NCT) and serves as the political and administrative center of the country. New Delhi was officially declared the capital in 1911, replacing Calcutta (now Kolkata), and has since been the seat of the Government of India, housing landmarks such as the **Rashtrapati Bhavan** (President's House), **Parliament House**, and **India Gate**. \n",
      "\n",
      "While Delhi as a region holds historical and cultural significance, New Delhi specifically is the modern capital. The city is renowned for its blend of tradition and modernity, as well as its role as a hub for government, diplomacy, and international events like the **Commonwealth Games**.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.utils.utils import secret_from_env\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import Field, SecretStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class ChatOpenRouter(ChatOpenAI):\n",
    "    openai_api_key: Optional[SecretStr] = Field(\n",
    "        alias=\"api_key\",\n",
    "        default_factory=secret_from_env(\"OPENROUTER_API_KEY\", default=None),\n",
    "    )\n",
    "    @property\n",
    "    def lc_secrets(self) -> dict[str, str]:\n",
    "        return {\"openai_api_key\": \"OPENROUTER_API_KEY\"}\n",
    "\n",
    "    def __init__(self,\n",
    "                 openai_api_key: Optional[str] = None,\n",
    "                 **kwargs):\n",
    "        openai_api_key = (\n",
    "            openai_api_key or os.environ.get(\"OPENROUTER_API_KEY\")\n",
    "        )\n",
    "        super().__init__(\n",
    "            base_url=\"https://openrouter.ai/api/v1\",\n",
    "            openai_api_key=openai_api_key,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "model = ChatOpenRouter(\n",
    "    model_name=\"qwen/qwen3-14b:free\"\n",
    ")\n",
    "\n",
    "result = model.invoke(\"What is the capital of India\")\n",
    "\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae7818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f4d1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861e61a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b07c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saumi\\anaconda3\\envs\\langchain-llama\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]c:\\Users\\saumi\\anaconda3\\envs\\langchain-llama\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\saumi\\.cache\\huggingface\\hub\\models--instruction-tuning-sd--cartoonizer. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 15 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [08:53<00:00, 35.57s/it]\n",
      "Keyword arguments {'use_auth_token': True} are not expected by StableDiffusionInstructPix2PixPipeline and will be ignored.\n",
      "Loading pipeline components...:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:03<00:04,  1.19s/it]An error occurred while trying to fetch C:\\Users\\saumi\\.cache\\huggingface\\hub\\models--instruction-tuning-sd--cartoonizer\\snapshots\\94ae1467bb3a3b231cb444ab0acd4295836014f1\\vae: Error no file named diffusion_pytorch_model.safetensors found in directory C:\\Users\\saumi\\.cache\\huggingface\\hub\\models--instruction-tuning-sd--cartoonizer\\snapshots\\94ae1467bb3a3b231cb444ab0acd4295836014f1\\vae.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:10<00:02,  2.31s/it]An error occurred while trying to fetch C:\\Users\\saumi\\.cache\\huggingface\\hub\\models--instruction-tuning-sd--cartoonizer\\snapshots\\94ae1467bb3a3b231cb444ab0acd4295836014f1\\unet: Error no file named diffusion_pytorch_model.safetensors found in directory C:\\Users\\saumi\\.cache\\huggingface\\hub\\models--instruction-tuning-sd--cartoonizer\\snapshots\\94ae1467bb3a3b231cb444ab0acd4295836014f1\\unet.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:18<00:00,  2.62s/it]\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionInstructPix2PixPipeline\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "model_id = \"instruction-tuning-sd/cartoonizer\"\n",
    "pipeline = StableDiffusionInstructPix2PixPipeline.from_pretrained(\n",
    "    model_id, torch_dtype=torch.float16, use_auth_token=True\n",
    ").to(\"cpu\")\n",
    "\n",
    "image_path = r\"C:\\Users\\saumi\\Downloads\\donald.jpeg\"\n",
    "image = load_image(image_path)\n",
    "\n",
    "image = pipeline(\"Cartoonize the following image\", image=image).images[0]\n",
    "image.save(\"image.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8be25da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
